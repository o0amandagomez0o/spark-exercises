{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "meaning-auction",
   "metadata": {},
   "source": [
    "# Spark Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-coach",
   "metadata": {},
   "source": [
    "## What is spark? When would we use it?\n",
    "\n",
    "- a tool for working with big data\n",
    "- big data?\n",
    "    - velocity\n",
    "    - volume\n",
    "    - variety\n",
    "    - veractiy\n",
    "- when do we use spark? when it is setup already\n",
    "- data too large for memory (or storage)\n",
    "- streaming data processing\n",
    "- alternatives: hadoop map-reduce, dask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-freeware",
   "metadata": {},
   "source": [
    "### Working in Parallel\n",
    "\n",
    "- great performance benefits\n",
    "- overhead associated with parallel work\n",
    "- faster at scale\n",
    "- within spark: executors and data partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-duncan",
   "metadata": {},
   "source": [
    "### Topics Covered\n",
    "\n",
    "- Overview\n",
    "- Env Setup\n",
    "- Spark API\n",
    "- Wrangle\n",
    "- Explore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mounted-orange",
   "metadata": {},
   "source": [
    "## How does spark work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-apache",
   "metadata": {},
   "source": [
    "### Architecture\n",
    "\n",
    "- scala on the JVM (Java Virtual Machine)\n",
    "- client libraries talk to spark instances\n",
    "    - all ends up as spark code\n",
    "    - Python, R, Scala, SQL\n",
    "- **Driver**, **Cluster Manager**, **Executors**, **Cluster**\n",
    "    - Cluster (a group of computers running spark)\n",
    "    - Driver (you or your teammates)\n",
    "    - Cluster Manager (a VM in the cloud that manages a spark cluster)\n",
    "    - Executor (one VM in a spark cluster)\n",
    "- (1+) Drivers -> (1) Cluster Manager -> (1+) Executors -> (1+) Data Partitions\n",
    "- Local Mode: everything runs on one machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competent-addition",
   "metadata": {},
   "source": [
    "### Spark DataFrames\n",
    "\n",
    "- slightly newer\n",
    "- like pandas dataframes\n",
    "- not like pandas dataframes -- spark dataframes are lazy\n",
    "- **transformations** and **actions**\n",
    "    - transformations: transform the data\n",
    "        - filter\n",
    "        - creating a new column\n",
    "        - group by\n",
    "    - actions: produce a result\n",
    "        - .head() -- .show()\n",
    "        - count\n",
    "- laziness can be efficient\n",
    "    - e.g. map -> filter to filter -> map\n",
    "    - e.g. group by -> mean -> filter to one group\n",
    "- shuffling: data from multiple partitions is needed, or data from multiple partitions needs to be *shuffled* around\n",
    "    - can be expensive\n",
    "    - do these last"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
